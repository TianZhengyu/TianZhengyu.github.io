<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>A Multimodal BiMamba Network with Test-Time Adaptation for Emotion Recognition Based on Physiological Signals</title>

  <link href="https://fonts.googleapis.com/css2?family=Montserrat:wght@300;600;800&display=swap" rel="stylesheet">

  <style>
    :root{
      --max-w: 1200px;
      --muted: #6b7280;
      --accent: #1f2937;
      --bg: #fff;
    }
    html,body{
      height:100%; margin:0; background:var(--bg);
      font-family:"Montserrat",system-ui,-apple-system,"Segoe UI",Roboto,"Helvetica Neue",Arial;
      color:#111827;
      -webkit-font-smoothing:antialiased;
      -moz-osx-font-smoothing:grayscale;
    }
    .container{
      max-width:var(--max-w);
      margin:0 auto;
      padding:48px 20px;
      display:flex;
      flex-direction:column;
      align-items:center;
    }
    header{ text-align:center; width:100%; }
    h1{
      margin:0;
      font-weight:800;
      line-height:1.04;
      letter-spacing:-0.02em;
      font-size:clamp(28px,6.5vw,56px);
      margin-bottom:18px;
    }
    .authors{
      color:var(--muted);
      font-size:15px;
      line-height:1.5;
      margin-bottom:8px;
    }
    .affil{
      color:var(--muted);
      font-size:14px;
      margin-top:8px;
    }
    .meta{
      margin-top:6px;
      color:var(--muted);
      font-size:14px;
    }
    .btns{
      margin-top:18px;
      display:flex;
      gap:12px;
      justify-content:center;
      align-items:center;
      flex-wrap:wrap;
    }
    .btn{
      display:inline-flex;
      align-items:center;
      gap:8px;
      padding:10px 16px;
      border-radius:999px;
      text-decoration:none;
      font-weight:600;
      font-size:15px;
      box-shadow:0 6px 18px rgba(15,23,42,0.06);
    }
    .btn-paper{
      background:var(--accent);
      color:#fff;
    }
    .btn-code{
      background:transparent;
      color:var(--accent);
      border:1px solid rgba(17,24,39,0.12);
    }

    main{
      width:100%;
      margin-top:36px;
      display:flex;
      flex-direction:column;
      align-items:center;
      gap:56px;
    }

    .figure-box{
      width:100%;
      border-radius:18px;
      border:3px dashed rgba(107,114,128,0.25);
      padding:22px;
      box-sizing:border-box;
      display:flex;
      justify-content:center;
      align-items:center;
      background:linear-gradient(180deg,rgba(255,255,255,0.6),rgba(255,255,255,0.4));
    }
    .figure-box img{
      max-width:100%;
      height:auto;
      border-radius:8px;
      display:block;
      box-shadow:inset 0 -6px 18px rgba(0,0,0,0.03);
    }
    /* 嵌入 module-all.pdf 的样式 */
    .figure-box iframe{
      width:100%;
      height:600px;
      border:0;
      border-radius:8px;
      box-shadow:inset 0 -6px 18px rgba(0,0,0,0.03);
    }
    /* 顶部 figure 说明文字样式（加粗） */
    .figure-caption-top{
      max-width:900px;
      margin:8px auto 0;
      font-size:17px;
      line-height:1.8;
      color:var(--muted);
      text-align:center;
      font-weight:600;
    }

    /* 通用小节样式 */
    .section{
      width:100%;
    }
    .section-title{
      text-align:center;
      font-size:26px;
      font-weight:700;
      margin:0 0 18px;
    }
    .section-subtitle{
      font-size:18px;
      font-weight:700;
      margin:0 0 8px;
    }
    .section-content{
      max-width:900px;
      margin:0 auto;
      font-size:16px;
      line-height:1.8;
      color:var(--muted);
    }
    .section--soft{
      padding:32px 20px;
      border-radius:18px;
      background:#f9fafb;
    }

    /* 方法块：图片在上，文字在下 */
    .method-block{
      max-width:1000px;
      margin:0 auto;
    }

    .figure-box.small{
      padding:16px;
    }

    .fig-caption{
      text-align:center;
      font-size:15px;
      color:var(--muted);
      margin-top:8px;
    }

    /* 视频部分 */
    .video-center{
      max-width:900px;
      margin:0 auto;
      text-align:center;
    }
    .video-tabs{
      display:inline-flex;
      border-radius:999px;
      border:1px solid #e5e7eb;
      overflow:hidden;
      margin-bottom:18px;
    }
    .video-tab{
      padding:8px 18px;
      font-size:15px;
      cursor:default;
      color:var(--muted);
      white-space:nowrap;
    }
    .video-tab.is-active{
      background:#111827;
      color:#fff;
    }
    .video-box{
      width:100%;
      margin:0 auto 12px;
    }
    .video-box video{
      width:100%;
      border-radius:14px;
      box-shadow:0 12px 32px rgba(15,23,42,0.25);
      background:#000;
    }
    .btn-row{
      margin-top:10px;
      display:flex;
      flex-wrap:wrap;
      justify-content:center;
      gap:12px;
    }

    /* Poster 区域 */
    .poster-frame{
      width:100%;
      max-width:1000px;
      height:480px;
      margin:0 auto;
      border-radius:14px;
      overflow:hidden;
      border:1px solid #e5e7eb;
      background:#f9fafb;
    }
    .poster-frame iframe{
      width:100%;
      height:100%;
      border:0;
    }

    /* BibTeX 区域 */
    .bibtex-block{
      max-width:1000px;
      margin:0 auto;
      background:#111827;
      color:#e5e7eb;
      padding:18px 20px;
      border-radius:14px;
      font-family:ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New";
      font-size:14px;
      overflow-x:auto;
      box-sizing:border-box;
    }

    footer{
      margin-top:32px;
      color:var(--muted);
      font-size:14px;
      text-align:center;
    }

    @media (max-width:640px){
      .container{ padding:28px 14px;}
      h1{ font-size:clamp(22px,8.5vw,34px);}
      .authors{font-size:14px;}
      .btn{padding:8px 12px;font-size:14px;}
      main{ gap:40px;}
      .poster-frame{ height:360px;}
    }
  </style>
</head>
<body>
  <div class="container">
    <header>
      <h1>
        A Multimodal BiMamba Network with Test-Time Adaptation<br>
        for Emotion Recognition Based on Physiological Signals
      </h1>

      <div class="authors">
        Ziyu Jia<sup>1,2</sup>, Tingyu Du<sup>3,4</sup>, Zhengyu Tian<sup>5</sup>, Hongkai Li<sup>5</sup>, Yong Zhang<sup>6*</sup>, Chenyu Liu<sup>7*</sup>
        <div class="affil">1 Institute of Automation, Chinese Academy of Sciences</div>
        <div class="affil">2 Shanghai Key Laboratory of Data Science</div>
        <div class="affil">3 Beijing Key Laboratory of Mobile Computing and Pervasive Devices, Institute of Computing Technology, Chinese Academy of Sciences</div>
        <div class="affil">4 University of Chinese Academy of Sciences</div>
        <div class="affil">5 School of Computer Science and Technology, Beijing Jiaotong University</div>
        <div class="affil">6 School of Information Engineering, Huzhou University</div>
        <div class="affil">7 College of Computing and Data Science, Nanyang Technological University</div>
      </div>
      <div class="meta">
        <div>NeurIPS 2025</div>
        <div style="color:var(--muted);font-size:14px">*Corresponding Author</div>
      </div>

      <div class="btns">
        <a class="btn btn-paper" href="extension://ngbkcglbmlglgldjfcnhaijeecaccgfi/https://openreview.net/pdf?id=3vLp3J7540">Paper</a>
        <a class="btn btn-code" href="https://neurips.cc/public/EthicsGuidelines">Code</a>
      </div>
    </header>

    <main>
      <!-- 顶部方法大图：嵌入同目录下的 module-all.pdf -->
      <section class="figure-box">
        <iframe src="module-all.pdf"></iframe>
      </section>

      <!-- 顶部 figure 描述文字（已加粗） -->
      <div class="figure-caption-top">
        In this paper, we propose a multimodal BiMamba network with TTA for emotion recognition. The multimodal BiMamba network effectively captures intra-modal dependencies and inter-modal correlations of multimodal physiological signals. The two-level entropy-based sample filtering and mutual information sharing across modalities achieve smooth adaptation to the target domain and reduce distribution shifts across modalities, thereby alleviating the negative impact of amplified distribution shifts caused by missing multimodal data.
      </div>

      <!-- Abstract 区 -->
      <section class="section section--soft">
        <h2 class="section-title">Abstract</h2>
        <div class="section-content">
          <p>
             Emotion recognition based on physiological signals plays a vital role in psychological health and human–computer interaction, particularly with the substantial advances in multimodal emotion recognition techniques. However, two key challenges remain unresolved: 1) how to effectively model the intra-modal long-range dependencies and inter-modal correlations in multimodal physiological emotion signals, and 2) how to address the performance limitations resulting from missing multimodal data. In this paper, we propose a multimodal bidirectional Mamba (BiMamba) network with test-time adaptation (TTA) for emotion recognition named BiM-TTA. Specifically, BiM-TTA consists of a multimodal BiMamba network and a multimodal TTA. The former includes intra-modal and inter-modal BiMamba modules, which model long-range dependencies along the time dimension and capture cross-modal correlations along the channel dimension, respectively. The latter (TTA) mitigates the amplified distribution shifts caused by missing multimodal data through two-level entropy-based sample filtering and mutual information sharing across modalities. By addressing these challenges, BiM-TTA achieves state-of-the-art results on two multimodal emotion datasets.
          </p>
        </div>
      </section>

      <!-- Methodology 区 -->
      <section class="section">
        <h2 class="section-title">Methodology</h2>

        <!-- 方法 1：MBiM Backbone，图片在上，文字在下 -->
        <div class="method-block">
          <div class="figure-box small">
            <img src="BiMamba-module.png" alt="BiMamba backbone illustration" />
          </div>
          <div class="fig-caption">
            Figure 1: The intra- and inter-modal BiMamba modules capture and fuse the features of different modalities, respectively. "Concat" represents the concatenation of multiple feature vectors u<sub>1</sub>, u<sub>2</sub>, ..., u<sub>M</sub>. T denotes matrix transposition.
          </div>
          <div class="section-content">
            <h3 class="section-subtitle">1. MBiM Backbone</h3>
            <p>
              这里用一两段话介绍 MBiM 作为多模态骨干网络的整体结构和设计动机，例如模态内长程依赖建模、模态间交互等。你可以后续把这部分替换为正式的英文介绍。
            </p>
          </div>
        </div>

        <!-- 方法 2：MMTTA，图片在上，文字在下 -->
        <div class="method-block" style="margin-top:32px">
          <div class="figure-box small">
            <img src="MMTTA.png" alt="MMTTA module illustration" />
          </div>
          <div class="fig-caption">
            Figure 2: Samples with weak distribution shifts and rich multimodal information are selected for adaptation, while the remaining samples are retained until the next iteration. Then, mutual information sharing across modalities is performed to match the information between different modalities effectively.
          </div>
          <div class="section-content">
            <h3 class="section-subtitle">2. Test-Time Adaptation with Entropy-Based Filtering</h3>
            <p>
              这里介绍 TTA 的目标函数、两级熵样本筛选思想以及如何与 MBiM 进行协同，例如如何缓解分布偏移、如何在缺失模态下稳健适应目标域。
            </p>
          </div>
        </div>
      </section>

      <!-- Video Presentation 区 -->
      <section class="section section--soft">
        <h2 class="section-title">Video Presentation</h2>
        <div class="video-center">
          <div class="video-tabs">
            <div class="video-tab is-active">English</div>
            <div class="video-tab">中文讲解</div>
          </div>

          <div class="video-box">
            <video controls>
              <source src="video_en.mp4" type="video/mp4">
              Your browser does not support the video tag.
            </video>
          </div>

          <div class="btn-row">
            <a class="btn btn-paper" href="#">Download English Slides (.pptx)</a>
            <a class="btn btn-code" href="#">下载中文PPT (.pptx)</a>
          </div>
        </div>
      </section>

      <!-- Poster 区：嵌入同目录下的 poster.pdf -->
      <section class="section">
        <h2 class="section-title">Poster</h2>
        <div class="poster-frame">
          <iframe src="poster.pdf"></iframe>
        </div>
      </section>

      <!-- BibTeX 区 -->
      <section class="section section--soft">
        <h2 class="section-title">BibTeX</h2>
        <pre class="bibtex-block">
@inproceedings{
jia2025a,
title={A Multimodal BiMamba Network with Test-Time Adaptation for Emotion Recognition Based on Physiological Signals},
author={Ziyu Jia and Tingyu Du and Zhengyu Tian and Hongkai Li and Yong Zhang and Chenyu Liu},
booktitle={The Thirty-ninth Annual Conference on Neural Information Processing Systems},
year={2025},
url={https://openreview.net/forum?id=3vLp3J7540}
}
        </pre>
      </section>
    </main>

    <footer>
      Built with simple HTML and CSS. Replace placeholder texts, images, video and poster links with your own content.
    </footer>
  </div>
</body>
</html>
